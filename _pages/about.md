---
permalink: /
title: "Mandar Joshi &#124; मंदार जोशी "
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a research scientist at [Google Brain](https://research.google/teams/brain/) in Seattle. My research interests are centered around self-supervised methods for natural language processing. 

Before joining Google, I completed my PhD at the [University of Washington](https://www.cs.washington.edu/) where I was advised my [Luke Zettlemoyer](https://www.cs.washington.edu/people/faculty/lsz) and [Dan Weld](https://www.cs.washington.edu/people/faculty/weld). When I am not doing Computer Science-y stuff, I like to hike, travel, and read.

Publications
======
* Kenton Lee\*, <b>Mandar Joshi</b>\*, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova. <a href="https://arxiv.org/abs/2210.03347" target="_blank"> Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding</a>. ArXiv 2210.03347, 2022.<br />
\* equal contribution

* <b>Mandar Joshi</b>, Terra Blevins, Mike Lewis, Daniel S. Weld, Luke Zettlemoyer. <a href="https://arxiv.org/abs/2205.04050" target="_blank"> Few-shot Mining of Naturally Occurring Inputs and Outputs </a>. ArXiv 2205.04050, 2022.

* Armen Aghajanyan, Bernie Huang, Candace Ross, Vladimir Karpukhin, Hu Xu, Naman Goyal, Dmytro Okhonko, <b>Mandar Joshi</b>, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer. <a href="https://arxiv.org/abs/2201.07520" target="_blank"> CM3: A Causal Masked Multimodal Model of the Internet </a>. ArXiv 2201.07520, 2022.

* Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, <b>Mandar Joshi</b>, Hu Xu, Gargi Ghosh, Luke Zettlemoyer. <a href="https://arxiv.org/abs/2107.06955" target="_blank"> HTLM: Hyper-Text Pre-Training and Prompting of Language Models</a>. ArXiv 2107.06955, 2021.

* Weijia Shi, <b>Mandar Joshi</b>, Luke Zettlemoyer. <a href="https://arxiv.org/abs/2106.05365" target="_blank"> DESCGEN: A Distantly Supervised Dataset for Generating Abstractive Entity Descriptions</a>. ACL 2021. 

* Arie Cattan, Alon Eirew, Gabriel Stanovsky, <b>Mandar Joshi</b>, Ido Dagan. <a href="https://arxiv.org/abs/2106.01210" target="_blank"> Cross-document Coreference Resolution over Predicted Mentions</a>. ACL 2021 Findings (Short). 

* Arie Cattan, Alon Eirew, Gabriel Stanovsky, <b>Mandar Joshi</b>, Ido Dagan. <a href="https://arxiv.org/abs/2009.11032" target="_blank"> Streamlining Cross-Document Coreference Resolution: Evaluation and Modeling</a>. ArXiv 2009.11032, 2020. 

* Terra Blevins, <b>Mandar Joshi</b>, Luke Zettlemoyer. <a href="https://arxiv.org/abs/2102.07983" target="_blank"> FEWS: Large-Scale, Low-Shot Word Sense Disambiguation with the Dictionary</a>. EACL 2021. 

* Bhargavi Paranjape, <b>Mandar Joshi</b>, John Thickstun, Hannaneh Hajishirzi, Luke Zettlemoyer. <a href="https://arxiv.org/abs/2005.00652" target="_blank"> An Information Bottleneck Approach to Controlling Conciseness in Rationale Extraction</a>. EMNLP, 2020.  [<a href="https://github.com/bhargaviparanjape/explainable_qa" target="_blank"> code </a>]

* <b>Mandar Joshi</b>, Kenton Lee, Yi Luan, Kristina Toutanova. <a href="https://arxiv.org/abs/2004.12006" target="_blank"> Contextualized Representations Using Textual Encyclopedic Knowledge</a>. ArXiv:2004.12006, 2020.  

* Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, <b>Mandar Joshi</b>, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. <a href="https://arxiv.org/abs/1907.11692" target="_blank">RoBERTa: A Robustly Optimized BERT Pretraining Approach </a>. ArXiv:1907.11692, 2019.  [<a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta" target="_blank"> code </a>]

* <b>Mandar Joshi</b>\*, Danqi Chen\*, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy. <a href="https://arxiv.org/abs/1907.10529" target="_blank"> SpanBERT: Improving Pre-training by Representing and Predicting Spans</a>. TACL, 2019.  Equal Contribution  [<a href="https://github.com/facebookresearch/SpanBERT" target="_blank"> code </a>]
<br />
\* equal contribution

* <b>Mandar Joshi</b>, Omer Levy, Daniel S. Weld, Luke Zettlemoyer. <a href="https://arxiv.org/abs/1908.09091" target="_blank">BERT for Coreference Resolution: Baselines and Analysis</a>. (Short) Proceedings of Emperical Methods in Natural Language Processing (EMNLP), 2019.  [<a href="https://github.com/mandarjoshi90/coref" target="_blank"> code </a>]

* <b>Mandar Joshi</b>, Eunsol Choi, Omer Levy, Daniel S. Weld, Luke Zettlemoyer. <a href = "https://arxiv.org/abs/1810.08854" target = "_blank">pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference</a>. Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2019.  [<a href="https://github.com/mandarjoshi90/pair2vec", target='_blank'> code </a>]

* <b>Mandar Joshi</b>, Eunsol Choi, Daniel Weld, Luke Zettlemoyer. <a href = "docs/triviaQA.pdf" target = "_blank">TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension</a>. Association for Computational Linguistics (ACL) 2017. [ <a href="http://nlp.cs.washington.edu/triviaqa/" target="_blank">website</a> ] [<a href="bibs/triviaqa.bib" target="_blank"> bib </a>]

* <b>Mandar Joshi</b>, Uma Sawant, Soumen Chakrabarti. <a href = "docs/proceedingsPaperEMNLP2014.pdf" target = "_blank">Knowledge Graph and Corpus Driven Segmentation and Answer Inference for Telegraphic Entity-seeking Queries</a>. Empirical Methods in Natural Language Processing (EMNLP) 2014.